{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 347,
     "referenced_widgets": [
      "f878e95150254b24a92f0db020f48846",
      "51cbcd4c30074e63a5a8dbd5e35041e7",
      "7a63cf6306864f978cc861f495741e60",
      "4a5b170ad98e48f98a4c26d731509ccc",
      "ce55ecc62bd04d89b9a6fe4f026b9ecd",
      "b49ffa4cbc0f48d78c1b7547e34bbec6",
      "da4da7abb17d41a0ad07d2271d8fdc30",
      "e62fc4188dcc4ad59f5a81f6d3f4b156",
      "6ce98a469bb549a781e527c4fe5f3ab9",
      "8ed82dc704a54dda90c252fb5d7b63e0",
      "9edf16d130a2499d8765c2d6296e239b",
      "17b8f99d521041a786c4c5a058f72b65",
      "abed0297178e436e937f1e325642a6c3",
      "548fa78a209b41fc8bc0d580fc21d6e1",
      "8bf69c971e714665966c4c6728b1cb28",
      "f1834304ee374dcdbe91c5d3f7f9b704",
      "ac4ee826e8c4492f82cfa3a723f91ef8",
      "ae0dc31d40304c219107b71992b0a26a",
      "ef42eba977dc4e7e8f3f417d4e14d69e",
      "da2cdc650d774354b8c4824e79508083",
      "d05103de1f7341949928f5a711e1a1eb",
      "52867641848f45ed8fa2f448a1f5ad65",
      "eaa865a954b94ce8b7b5b9b6aca35bc9",
      "1bb16742cf254edba8c12313da3b9a36",
      "3d40d000269746d6b205b39c5bbf8784",
      "6c4142aecc0a4a4da59a4b179164bd0f",
      "8f21f714f3634b08b977c6a8242a7807",
      "553744f46292497891f45c38a8e26dfa",
      "ced7113e0a9449ae8bc5cdd78e5b0347",
      "ca6eeef7db094abbb87d31aaa47d5b30",
      "29863f3407404a2ea96411183599e71a",
      "edd27585bc204ef5ae0faa102b05c4b7",
      "8aed9086e3414b2aa6b03dc34cf515f3"
     ]
    },
    "id": "iTGmpcG-HRmw",
    "outputId": "887c3d27-f1cb-45f9-af77-bda56f8ec333"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"sms_spam\")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "82_fb6ahIkHK",
    "outputId": "46135c56-fa31-4983-bbe6-ff728f91526d"
   },
   "outputs": [],
   "source": [
    "print(dataset['train'][8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1TwuOSObWHvr",
    "outputId": "ae5157fc-074f-45d3-a449-90ce590c8466"
   },
   "outputs": [],
   "source": [
    "print(dataset['train'].features['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "hNVT_nU5ZRar"
   },
   "source": [
    "#investigating TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LAGJ_jIrZYcp",
    "outputId": "ed48c0e7-f66c-45f6-e2b6-ffd6f5f90d63"
   },
   "outputs": [],
   "source": [
    "text = [\n",
    "    \"I won the lottery\",\n",
    "    \"you won a lottery\",\n",
    "    \"Congratulations! we are happy to offer you SDE-1 role at Amazon\"\n",
    "]\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words = 'english', max_features = 500)\n",
    "X = vectorizer.fit_transform(text)\n",
    "\n",
    "print(\"shappe of TF-IDF matrix:\", X.shape)\n",
    "print(\"Example of feature names:\", vectorizer.get_feature_names_out()[:20])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "id": "JkVjPZ0Rbm1d"
   },
   "source": [
    "Vectorizing the dataset! getting ready for that prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CBK5uKWnblJa",
    "outputId": "5a95b4f9-43b5-47ec-a6d9-b5bb1b8ece76"
   },
   "outputs": [],
   "source": [
    "# doing the split with Hugging Face to avoid weird indexing issues\n",
    "splits = dataset['train'].train_test_split(test_size=0.2, seed=42, stratify_by_column='label')\n",
    "\n",
    "# pulling out the text and labels as plain lists (keeping it simple)\n",
    "train_texts = list(splits['train']['sms'])\n",
    "train_labels = list(map(int, splits['train']['label']))\n",
    "test_texts  = list(splits['test']['sms'])\n",
    "test_labels = list(map(int, splits['test']['label']))\n",
    "\n",
    "# vectorizing with tf-idf — small cap on features to stay fast\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# fitting on train only, then applying to test\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "X_test  = vectorizer.transform(test_texts)\n",
    "\n",
    "# sanity check — rows = docs, cols = vocab size\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test  shape:\", X_test.shape)\n",
    "\n",
    "# quick peek at what words made it in\n",
    "print(\"Example features:\", vectorizer.get_feature_names_out()[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IZztea4Xd1oX",
    "outputId": "5b4216e3-d5cb-47fb-c7d7-4789e6163a9c"
   },
   "outputs": [],
   "source": [
    "# training a simple baseline so I have a reference point\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# fitting the model on the tf-idf features\n",
    "clf = LogisticRegression(max_iter=2000, n_jobs=-1)  # cranking up max_iter just in case\n",
    "clf.fit(X_train, train_labels)\n",
    "\n",
    "# getting predictions on the test set to see how well it generalizes\n",
    "test_pred = clf.predict(X_test)\n",
    "\n",
    "# quick metrics to get the vibe (accuracy + macro-F1 for imbalance)\n",
    "acc = accuracy_score(test_labels, test_pred)\n",
    "f1  = f1_score(test_labels, test_pred, average='macro')\n",
    "print(\"test accuracy:\", acc)\n",
    "print(\"macro-F1:\", f1)\n",
    "print(\"\\nclassification report:\\n\", classification_report(test_labels, test_pred, digits=3, target_names=[\"ham\",\"spam\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "N9Gmn5BPfVrH",
    "outputId": "cc1ebddd-0dd7-4d10-dc5b-19f859cba43d"
   },
   "outputs": [],
   "source": [
    "# drawing the confusion matrix to see *how* it’s making mistakes\n",
    "cm = confusion_matrix(test_labels, test_pred, labels=[0,1])  # 0=ham, 1=spam\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"ham\",\"spam\"])\n",
    "disp.plot(values_format=\"d\")\n",
    "plt.title(\"TF-IDF + LogisticRegression — Confusion Matrix\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
